import cv2 # computer vision :for various image and video processing tasks.
# It's commonly used for tasks like image manipulation, object detection, face recognition, and more.

from tensorflow.keras.models import Sequential # essential for building a sequential neural network model in Keras.

from tensorflow.keras.layers import Conv2D,MaxPooling2D,Dropout,Flatten,Dense
# Conv2D is used for convolutional operations, which are fundamental in CNNs for extracting features from images.
# MaxPooling2D is used for downsampling the spatial dimensions of the input.It helps reduce the computational complexity and control overfitting by retaining the most important information.
# Dropout used to prevent overfitting by randomly setting a fraction of input units to 0 at each update during training.
# Flatten is used to reshape the data from a multi-dimensional tensor into a 1D array
# Dense represents a fully connected layer, where each neuron is connected to all neurons

from tensorflow.keras.optimizers import Adam # build and compile a neural network model
from tensorflow.keras.preprocessing.image import ImageDataGenerator
#generating batches of augmented image data,which is commonly used for training deep learning models.
# particularly for computer vision tasks like image classification and object detection.

import numpy as np
# unzip the dataset
!unzip -uq "/content/drive/MyDrive/face mask/archive1-220321-141335.zip" -d "/content/drive/MyDrive/face mask/archive"
#store each paths to corresponding variables for easy usage
import os
main_dir="/content/drive/MyDrive/face mask/archive/New Masks Dataset"
train_dir=os.path.join(main_dir,'Train')
test_dir=os.path.join(main_dir,'Test')
valid_dir=os.path.join(main_dir,'Validation')

train_mask_dir=os.path.join(train_dir,'Mask')
train_nomask_dir=os.path.join(train_dir,'Non Mask')
test_mask_dir=os.path.join(test_dir,'Mask')
test_nomask_dir=os.path.join(test_dir,'Non Mask')
valid_mask_dir=os.path.join(valid_dir,'Mask')
valid_nomask_dir=os.path.join(valid_dir,'Non Mask')

valid_nomask_dir
test_nomask_dir
#optional
train_mask_names=os.listdir(train_mask_dir)
train_nomask_names=os.listdir(train_nomask_dir)
train_nomask_names[1:10]

train_datagen= ImageDataGenerator(rescale=1.0/255, #brings the pixel values into the range of [0, 1]
                                  zoom_range=0.2,
                                  rotation_range=40,
                                  horizontal_flip = True)
test_datagen=ImageDataGenerator(rescale=1.0/255)
validation_datagen=ImageDataGenerator(rescale=1.0/255)

train_generator=train_datagen.flow_from_directory(train_dir,
                                                  target_size=(150,150),#(width,height)
                                                  batch_size=32, #no of images in each batch
                                                  class_mode='binary') #class_index
test_generator=test_datagen.flow_from_directory(test_dir,
                                                  target_size=(150,150),
                                                  batch_size=32,
                                                  class_mode='binary')
valid_generator=validation_datagen.flow_from_directory(valid_dir,
                                                  target_size=(150,150),
                                                  batch_size=32,
                                                  class_mode='binary') #two types : binary,categorical
train_generator.class_indices
train_generator.image_shape


# Create a Sequential model
model = Sequential()

# Add layers to the model
model.add(Conv2D(32, (3, 3), padding='SAME', activation='relu', input_shape=(150, 150, 3)))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.5))
model.add(Conv2D(64, (3, 3), padding='SAME', activation='relu'))
model.add(MaxPooling2D((2, 2)))
model.add(Dropout(0.5))

model.add(Flatten())

model.add(Dense(256, activation='relu'))
model.add(Dropout(0.5))
model.add(Dense(1, activation='sigmoid'))  # Binary classification, so using sigmoid activation

model.summary()

model.compile(optimizer=Adam(lr=0.001), loss='binary_crossentropy', metrics=['accuracy'])
history=model.fit(train_generator,
                  epochs=30,
                  validation_data = valid_generator)
test_loss,test_acc=model.evaluate(test_generator)
print('test acc :{} test loss : {}'.format(test_acc,test_loss))
import numpy as np
from google.colab import files
from keras.preprocessing import image

uploaded=files.upload()
for f in uploaded.keys():
  image_path='/content'+f
  img=image.load_img(image_path,target_size=(150,150))
  images=image.img_to_array(img)
  #images=np.expand_dims(images,axis=0)
  prediction=model.predict(images)
  if(prediction==0):
    print(f,"mask is there")
  else:
    print(f,"no mask is present")

import numpy as np
from google.colab import files
from keras.preprocessing.image import load_img

# Assuming 'model' is already defined and loaded with your trained model

uploaded = files.upload()
for f in uploaded.keys():
    image_path = '/content/' + f
    img = image.load_img(image_path, target_size=(150, 150))
    img_array = image.img_to_array(img)  # Changed 'images' to 'img_array'
    img_array = np.expand_dims(img_array, axis=0)  # Expanding dimensions

    prediction = model.predict(img_array)
    if prediction == 0:
        print(f, "mask is there")
    else:
        print(f, "no mask is present")

model.save('saved_model07.h5')
